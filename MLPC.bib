@misc{P3,
author = "Tobias Grosser, Johannes Doerfert, Zino Benaissa",
title = "Analyzing and Optimizing your Loops with Polly",
url = {https://www.llvm.org/devmtg/2016-03/Tutorials/applied-polyhedral-compilation.pdf},    
note = {EuroLLVM 2016, 17. March, Barcelona},
}

@article{P2,
author = {Geist, Matthieu and Pietquin, Olivier},
year = {2013},
month = {06},
pages = {},
title = {An Algorithmic Survey of Parametric Value Function Approximation},
volume = {24},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
doi = {10.1109/TNNLS.2013.2247418}
}

@inproceedings{P1,
   author = {Brauckmann, A. and Goens, A. and Castrillon, J.},
   title = {PolyGym: Polyhedral Optimizations as an Environment for Reinforcement Learning},
   booktitle = {2021 30th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
   pages = {17-29},
   DOI = {10.1109/PACT52795.2021.00009},
   type = {Conference Proceedings}
}

@inproceedings{poly_applicable,
    author = {Benabderrahmane, Mohamed-Walid and Pouchet, Louis-Noël and Cohen, Albert and Bastoul, Cédric},
    year = {2010},
    month = {03},
    pages = {283-303},
    title = {The Polyhedral Model Is More Widely Applicable Than You Think},
    volume = {6011},
    isbn = {978-3-642-11969-9},
    doi = {10.1007/978-3-642-11970-5_16}
}



@article{DeepMind,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei and Veness, Joel and Bellemare, Marc and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
year = {2015},
month = {02},
pages = {529-33},
title = {Human-level control through deep reinforcement learning},
volume = {518},
journal = {Nature},
doi = {10.1038/nature14236}
}

@misc{Gym,
  doi = {10.48550/ARXIV.1606.01540},
  url = {https://arxiv.org/abs/1606.01540},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {OpenAI Gym},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{AlphaGo,
author = {Silver, David and Huang, Aja and Maddison, Christopher and Guez, Arthur and Sifre, Laurent and Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
year = {2016},
month = {01},
pages = {484-489},
title = {Mastering the game of Go with deep neural networks and tree search},
volume = {529},
journal = {Nature},
doi = {10.1038/nature16961}
}

@article{single,
author = {Feautrier, Paul},
year = {1996},
month = {08},
pages = {},
title = {Some efficient solutions to the affine scheduling problem Part I One-dimensional Time},
volume = {21},
journal = {International Journal of Parallel Programming},
doi = {10.1007/BF01407835}
}

@article{multi,
author = {Feautrier, Paul},
year = {1997},
month = {01},
pages = {},
title = {Some efficient solutions to the affine scheduling problem Part II Multidimensional time},
volume = {21},
journal = {International Journal of Parallel Programming},
doi = {10.1007/BF01379404}
}

@INPROCEEDINGS{it_Single,
  author={Pouchet, Louis-Noel and Bastoul, Cedric and Cohen, Albert and Vasilache, Nicolas},
  booktitle={International Symposium on Code Generation and Optimization (CGO'07)}, 
  title={Iterative Optimization in the Polyhedral Model: Part I, One-Dimensional Time}, 
  year={2007},
  volume={},
  number={},
  pages={144-156},
  doi={10.1109/CGO.2007.21}}

@inproceedings{it_multi,
author = {Pouchet, Louis-No\"{e}l and Bastoul, C\'{e}dric and Cohen, Albert and Cavazos, John},
title = {Iterative Optimization in the Polyhedral Model: Part Ii, Multidimensional Time},
year = {2008},
isbn = {9781595938602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375581.1375594},
doi = {10.1145/1375581.1375594},
booktitle = {Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {90–100},
numpages = {11},
keywords = {affine scheduling, genetic algorithm, loop transformation, iterative compilation},
location = {Tucson, AZ, USA},
series = {PLDI '08}
}

@article{10.1145/3109482,
author = {Ganser, Stefan and Gr\"{o}sslinger, Armin and Siegmund, Norbert and Apel, Sven and Lengauer, Christian},
title = {Iterative Schedule Optimization for Parallelization in the Polyhedron Model},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1544-3566},
url = {https://doi.org/10.1145/3109482},
doi = {10.1145/3109482},
journal = {ACM Trans. Archit. Code Optim.},
month = {aug},
articleno = {23},
numpages = {26},
keywords = {tiling, parallelization, OpenMP, Automatic loop optimization, polyhedron model, genetic algorithm}
}

@article{10.1145/3291773,
author = {Ganser, Stefan and Gr\"{o}\ss{}linger, Armin and Siegmund, Norbert and Apel, Sven and Lengauer, Christian},
title = {Speeding up Iterative Polyhedral Schedule Optimization with Surrogate Performance Models},
year = {2018},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3291773},
doi = {10.1145/3291773},
journal = {ACM Trans. Archit. Code Optim.},
month = {dec},
articleno = {56},
numpages = {27},
keywords = {polyhedron model, CART, tiling, parallelization, random forests, Automatic loop optimization, supervised learning, genetic algorithm, OpenMP}
}

@misc{10.48550,
  doi = {10.48550/ARXIV.2101.04808},
  url = {https://arxiv.org/abs/2101.04808},
  author = {Trofin, Mircea and Qian, Yundi and Brevdo, Eugene and Lin, Zinan and Choromanski, Krzysztof and Li, David},
  keywords = {Programming Languages (cs.PL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MLGO: a Machine Learning Guided Compiler Optimizations Framework},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}



  

@INPROCEEDINGS{10.1007,
author = {Emani, Murali and O'Boyle, Michael},
year = {2014},
month = {09},
pages = {},
title = {Change Detection Based Parallelism Mapping: Exploiting Offline Models and Online Adaptation},
doi = {10.1007/978-3-319-17473-0_14}
}

@ARTICLE{8357388,
  author={Wang, Zheng and O’Boyle, Michael},
  journal={Proceedings of the IEEE},
  title={Machine Learning in Compiler Optimization},
  year={2018},
  volume={106},
  number={11},
  pages={1879-1901},
  doi={10.1109/JPROC.2018.2817118}}
  
@INPROCEEDINGS{9232934,  author={Leather, Hugh and Cummins, Chris},  booktitle={2020 Forum for Specification and Design Languages (FDL)},   title={Machine Learning in Compilers: Past, Present and Future},   year={2020},  volume={},  number={},  pages={1-8},  doi={10.1109/FDL50818.2020.9232934}}

@inbook{NeuroVectorizer,
author = {Haj-Ali, Ameer and Ahmed, Nesreen K. and Willke, Ted and Shao, Yakun Sophia and Asanovic, Krste and Stoica, Ion},
title = {NeuroVectorizer: End-to-End Vectorization with Deep Reinforcement Learning},
year = {2020},
isbn = {9781450370479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368826.3377928},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {242–255},
numpages = {14}
}

@misc{static.neural,
  doi = {10.48550/ARXIV.2008.08951},
  url = {https://arxiv.org/abs/2008.08951},
  author = {Mammadli, Rahim and Jannesari, Ali and Wolf, Felix},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Static Neural Compiler Optimization via Deep Reinforcement Learning},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{CompilerGym,
      title={{CompilerGym: Robust, Performant Compiler Optimization Environments for AI Research}},
      author={Chris Cummins and Bram Wasti and Jiadong Guo and Brandon Cui and Jason Ansel and Sahir Gomez and Somya Jain and Jia Liu and Olivier Teytaud and Benoit Steiner and Yuandong Tian and Hugh Leather},
      journal={arXiv:2109.08267},
      year={2021},
}

@article{DBLP:journals/corr/MnihKSGAWR13,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  eprinttype = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{polybench,
    author = "L.-N. Pouchet et al. (2012)",
    title = "Polybench: The polyhedral benchmark suite",
	url = {http://web.cs.ucla.edu/∼pouchet/software/polybench/},    
    note = {Available: http://web.cs.ucla.edu/pouchet/software/polybench}
}

@InProceedings{isl,
author="Verdoolaege, Sven",
editor="Fukuda, Komei
and Hoeven, Joris van der
and Joswig, Michael
and Takayama, Nobuki",
title="isl: An Integer Set Library for the Polyhedral Model",
booktitle="Mathematical Software -- ICMS 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="299--302",
isbn="978-3-642-15582-6"
}

@TECHREPORT{Bondhugula07pluto:a,
    author = {Uday Bondhugula and J. Ramanujam},
    title = {Pluto: A practical and fully automatic polyhedral parallelizer and locality optimizer},
    institution = {},
    year = {2007}
}

@article{BHATNAGAR20092471,
title = {Natural actor–critic algorithms},
journal = {Automatica},
volume = {45},
number = {11},
pages = {2471-2482},
year = {2009},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2009.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0005109809003549},
author = {Shalabh Bhatnagar and Richard S. Sutton and Mohammad Ghavamzadeh and Mark Lee},
keywords = {Actor–critic reinforcement learning algorithms, Policy-gradient methods, Approximate dynamic programming, Function approximation, Two-timescale stochastic approximation, Temporal difference learning, Natural gradient},
}

@misc{DDQN,
  doi = {10.48550/ARXIV.1509.06461},
  url = {https://arxiv.org/abs/1509.06461},
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Reinforcement Learning with Double Q-learning},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{10.1145/5666.5673,
author = {Fleming, Philip J. and Wallace, John J.},
title = {How Not to Lie with Statistics: The Correct Way to Summarize Benchmark Results},
year = {1986},
issue_date = {March 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/5666.5673},
doi = {10.1145/5666.5673},
abstract = {Using the arithmetic mean to summarize normalized benchmark results leads to mistaken conclusions that can be avoided by using the preferred method: the geometric mean.},
journal = {Commun. ACM},
month = {mar},
pages = {218–221},
numpages = {4}
}

@ARTICLE{580874,

  author={Tsitsiklis, J.N. and Van Roy, B.},

  journal={IEEE Transactions on Automatic Control}, 

  title={An analysis of temporal-difference learning with function approximation}, 

  year={1997},

  volume={42},

  number={5},

  pages={674-690},

  doi={10.1109/9.580874}
}

@article{ER,
   author = {Lin, Long-Ji},
   title = {Self-improving reactive agents based on reinforcement learning, planning and teaching},
   journal = {Machine Learning},
   volume = {8},
   number = {3},
   pages = {293-321},
   abstract = {To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.},
   ISSN = {1573-0565},
   DOI = {10.1007/BF00992699},
   url = {https://doi.org/10.1007/BF00992699},
   year = {1992},
   type = {Journal Article}
}

@article{RAMICIC202091,
title = {Correlation minimizing replay memory in temporal-difference reinforcement learning},
journal = {Neurocomputing},
volume = {393},
pages = {91-100},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S092523122030179X},
author = {Mirza Ramicic and Andrea Bonarini},
keywords = {Reinforcement learning, Temporal-difference learning, Replay memory, Artificial neural networks},
abstract = {Online reinforcement learning agents are now able to process an increasing amount of data which makes their approximation and compression into value functions a more demanding task. To improve approximation, thus the learning process itself, it has been proposed to select randomly a mini-batch of the past experiences that are stored in the replay memory buffer to be replayed at each learning step. In this work, we present an algorithm that classifies and samples the experiences into separate contextual memory buffers using an unsupervised learning technique. This allows each new experience to be associated to a mini-batch of the past experiences that are not from the same contextual buffer as the current one, thus further reducing the correlation between experiences. Experimental results show that the correlation minimizing sampling improves over Q-learning algorithms with uniform sampling, and that a significant improvement can be observed when coupled with the sampling methods that prioritize on the experience temporal difference error.}
}

@inbook{inbook,
author = {Webb, Geoffrey and Sammut, Claude and Perlich, Claudia and Horváth, Tamás and Wrobel, Stefan and Korb, Kevin and Noble, William and Leslie, Christina and Lagoudakis, Michail and Quadrianto, Novi and Buntine, Wray and Getoor, Lise and Namata, Galileo and Jin, Jiawei and Ting, Jo-Anne and Vijayakumar, Sethu and Schaal, Stefan and De Raedt, Luc},
year = {2010},
month = {01},
pages = {},
title = {Leave-One-Out Cross-Validation},
doi = {10.1007/978-0-387-30164-8_469}
}

@book{GA,
author = {Yang, Xin-She},
year = {2010},
month = {07},
pages = {},
title = {Nature-Inspired Metaheuristic Algorithms}
}

@inproceedings{OpenMPI,
author = {Graham, Richard and Woodall, Timothy and Squyres, Jeffrey},
year = {2005},
month = {09},
pages = {228-239},
title = {Open MPI: A flexible high performance MPI},
isbn = {978-3-540-34141-3},
doi = {10.1007/11752578_29}
}

@techreport{leverge:inria-00074895,
  TITLE = {{A Note on Chernikova's algorithm}},
  AUTHOR = {Le Verge, Herv{\'e}},
  URL = {https://inria.hal.science/inria-00074895},
  TYPE = {Research Report},
  NUMBER = {RR-1662},
  INSTITUTION = {{INRIA}},
  YEAR = {1992},
  PDF = {https://inria.hal.science/inria-00074895/file/RR-1662.pdf},
  HAL_ID = {inria-00074895},
  HAL_VERSION = {v1},
}

@article{10.5555/261410.261418,
author = {Barvinok, Alexander},
title = {Approximate Counting via Random Optimization},
year = {1997},
issue_date = {Sept. 1997},
publisher = {John Wiley & Sons, Inc.},
address = {USA},
volume = {11},
number = {2},
issn = {1042-9832},
journal = {Random Struct. Algorithms},
month = {sep},
pages = {187–198},
numpages = {12},
keywords = {concentration of measure, average case in optimization, approximate counting}
}

@inproceedings{grosser2011polly,
  title={Polly-Polyhedral optimization in LLVM},
  author={Grosser, Tobias and Zheng, Hongbin and Aloor, Raghesh and Simb{\"u}rger, Andreas and Gr{\"o}{\ss}linger, Armin and Pouchet, Louis-No{\"e}l}
}

@article{PolyOpt,
author = {Lengauer, Christian},
year = {2012},
month = {12},
pages = {},
title = {Polly---Performing Polyhedral Optimizations on a Low-Level Intermediate Representation},
volume = {22},
journal = {Parallel Processing Letters},
doi = {10.1142/S0129626412500107}
}

@book{schrijver1998theory,
  title={Theory of linear and integer programming},
  author={Schrijver, Alexander},
  year={1998},
  publisher={John Wiley \& Sons}
}

@article{10.1145/2743016,
author = {Grosser, Tobias and Verdoolaege, Sven and Cohen, Albert},
title = {Polyhedral AST Generation Is More Than Scanning Polyhedra},
year = {2015},
issue_date = {August 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {4},
issn = {0164-0925},
url = {https://doi.org/10.1145/2743016},
doi = {10.1145/2743016},
abstract = {Abstract mathematical representations such as integer polyhedra have been shown to be useful to precisely analyze computational kernels and to express complex loop transformations. Such transformations rely on abstract syntax tree (AST) generators to convert the mathematical representation back to an imperative program. Such generic AST generators avoid the need to resort to transformation-specific code generators, which may be very costly or technically difficult to develop as transformations become more complex. Existing AST generators have proven their effectiveness, but they hit limitations in more complex scenarios. Specifically, (1) they do not support or may fail to generate control flow for complex transformations using piecewise schedules or mappings involving modulo arithmetic; (2) they offer limited support for the specialization of the generated code exposing compact, straightline, vectorizable kernels with high arithmetic intensity necessary to exploit the peak performance of modern hardware; (3) they offer no support for memory layout transformations; and (4) they provide insufficient control over the AST generation strategy, preventing their application to complex domain-specific optimizations.We present a new AST generation approach that extends classical polyhedral scanning to the full generality of Presburger arithmetic, including existentially quantified variables and piecewise schedules, and introduce new optimizations for the detection of components and shifted strides. Not limiting ourselves to control flow generation, we expose functionality to generate AST expressions from arbitrary piecewise quasi-affine expressions, which enables the use of our AST generator for data-layout transformations. We complement this with support for specialization by polyhedral unrolling, user-directed versioning, and specialization of AST expressions according to the location at which they are generated, and we complete this work with fine-grained user control over the AST generation strategies used. Using this generalized idea of AST generation, we present how to implement complex domain-specific transformations without the need to write specialized code generators, but instead relying on a generic AST generator parametrized to a specific problem domain.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {jul},
articleno = {12},
numpages = {50},
keywords = {index set splitting, Polyhedral compilation, code generation, Presburger relations, unrolling}
}

@article{compilerresearch,
author = {Hall, Mary and Padua, David and Pingali, Keshav},
year = {2009},
month = {02},
pages = {60-67},
title = {Compiler Research: The Next 50 Years},
volume = {52},
journal = {Commun. ACM},
doi = {10.1145/1461928.1461946}
}

@inproceedings{inproceedingsdl,
author = {Cummins, Chris and Petoumenos, Pavlos and Wang, Zheng and Leather, Hugh},
year = {2017},
month = {09},
pages = {219-232},
title = {End-to-End Deep Learning of Optimization Heuristics},
doi = {10.1109/PACT.2017.24}
}

@inproceedings{inproceedingsml,
author = {Jimenez, Daniel and Hanson, Heather and Lin, C.T.},
year = {2001},
month = {02},
pages = {97-106},
title = {Boolean formula-based branch prediction for future technologies},
isbn = {0-7695-1363-8},
doi = {10.1109/PACT.2001.953291}
}

@INPROCEEDINGS{9232946,

  author={Brauckmann, Alexander and Goens, Andrés and Castrillon, Jeronimo},

  booktitle={2020 Forum for Specification and Design Languages (FDL)}, 

  title={ComPy-Learn: A toolbox for exploring machine learning representations for compilers}, 

  year={2020},

  volume={},

  number={},

  pages={1-4},

  doi={10.1109/FDL50818.2020.9232946}}

@Inbook{Wiewiora2010,
author="Wiewiora, Eric",
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="Reward Shaping",
bookTitle="Encyclopedia of Machine Learning",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="863--865",
isbn="978-0-387-30164-8",
doi="10.1007/978-0-387-30164-8_731",
url="https://doi.org/10.1007/978-0-387-30164-8_731"
}

